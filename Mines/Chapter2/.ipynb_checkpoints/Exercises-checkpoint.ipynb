{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"income_cat\"] = pd.cut(data.median_income, bins = np.array([0, 1.5, 3, 4.5, 6, np.inf]),\n",
    "                           labels = np.arange(1,6))\n",
    "#creando los indicadores según el ingreso medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando los conjuntos de entrenamiento y prueba\n",
    "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = 42)\n",
    "for train_index, test_index in split.split(data, data.income_cat):\n",
    "    train_set = data.iloc[train_index]\n",
    "    test_set = data.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#borrando el indicador creado en los conjuntos ya definidos\n",
    "for set_ in (train_set, test_set): \n",
    "    set_.drop(\"income_cat\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando las clases que se van a neceitar para la preparación de los datos\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16512 entries, 17606 to 15775\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           16512 non-null  float64\n",
      " 1   latitude            16512 non-null  float64\n",
      " 2   housing_median_age  16512 non-null  float64\n",
      " 3   total_rooms         16512 non-null  float64\n",
      " 4   total_bedrooms      16354 non-null  float64\n",
      " 5   population          16512 non-null  float64\n",
      " 6   households          16512 non-null  float64\n",
      " 7   median_income       16512 non-null  float64\n",
      " 8   median_house_value  16512 non-null  float64\n",
      " 9   ocean_proximity     16512 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rooms_per_household \n",
    "population_per_household\n",
    "bedrooms_per_room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando la clase para el transformador personalizado\n",
    "\n",
    "class Custom(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, 3] / X[:, 6]\n",
    "        population_per_household = X[:, 5] / X[:, 6]\n",
    "        bedrooms_per_room = X[:, 4] / X[:, 3]\n",
    "        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando el pipeline para los atributos numericos\n",
    "numpipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy = \"median\")), \n",
    "    (\"new_attrs\", Custom()),\n",
    "    (\"scale\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitando los valores de la variable respuesta \n",
    "housing = train_set.drop(columns = [\"median_house_value\"])\n",
    "housing_labels = train_set.median_house_value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando el transformador en simultaneo \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#extrayendo atributos de cada clase\n",
    "num = list(housing)[:-1]\n",
    "cat = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", numpipeline, num), \n",
    "    (\"cat\", OneHotEncoder(), cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando los objetos de la clase SVR para ajustarlos con diferentes hiperparametros\n",
    "from sklearn.svm import SVR\n",
    "sv1 = SVR(kernel = \"linear\", C = 0.5)\n",
    "sv2 = SVR(kernel = \"rbf\", gamma = \"auto\")\n",
    "sv3 = SVR(kernel = \"rbf\", C = 1.25)\n",
    "sv4 = SVR(kernel = \"linear\", gamma = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajustando los predictores con el metodo fit de la clase SVR\n",
    "sv1.fit(housing_prepared, housing_labels)\n",
    "sv2.fit(housing_prepared, housing_labels)\n",
    "sv3.fit(housing_prepared, housing_labels)\n",
    "sv4.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errores sobre el mismo conjunto de datos\n",
    "errors = [mse(sv1.predict(housing_prepared), housing_labels),\n",
    "mse(sv2.predict(housing_prepared), housing_labels),\n",
    "mse(sv3.predict(housing_prepared), housing_labels),\n",
    "mse(sv4.predict(housing_prepared), housing_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Mean Root Error of the SVR number 1 is 114783.24481875032\n",
      "the Mean Root Error of the SVR number 2 is 118577.43356412371\n",
      "the Mean Root Error of the SVR number 3 is 118490.9969603456\n",
      "the Mean Root Error of the SVR number 4 is 111094.6308539982\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for error in errors:\n",
    "    print(f\"the Mean Root Error of the SVR number {counter} is {np.sqrt(error)}\")\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando k-fold cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def display_scores(scores):\n",
    "    scores = np.sqrt(-scores)\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrs = [\n",
    "SVR(kernel = \"linear\", C = 0.5),\n",
    "SVR(kernel = \"rbf\", gamma = \"auto\"),\n",
    "SVR(kernel = \"rbf\", C = 1.25),\n",
    "SVR(kernel = \"linear\", gamma = \"auto\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [108367.74151582 115959.28059807 113501.53452598 116899.04847892\n",
      " 114105.7235789  118996.07243651 114127.99044335 117944.67740229\n",
      " 117020.37482429 114779.59582688]\n",
      "Mean: 115170.20396310164\n",
      "Standard deviation: 2842.525377445233\n",
      "Scores: [111393.33263237 119546.71049753 116961.00489445 120449.0155974\n",
      " 117622.20149716 122303.76986818 117640.09907103 121459.63518806\n",
      " 120348.51364519 118025.61954959]\n",
      "Mean: 118574.99024409598\n",
      "Standard deviation: 2934.1329433145675\n",
      "Scores: [111318.59887512 119448.73860597 116879.83568467 120368.36415403\n",
      " 117530.0985779  122214.45389338 117555.52653298 121396.78405107\n",
      " 120268.87957107 117933.66786749]\n",
      "Mean: 118491.4947813692\n",
      "Standard deviation: 2933.5737961815034\n",
      "Scores: [105342.09141998 112489.24624123 110092.35042753 113403.22892482\n",
      " 110638.90119657 115675.8320024  110703.56887243 114476.89008206\n",
      " 113756.17971227 111520.1120808 ]\n",
      "Mean: 111809.84009600841\n",
      "Standard deviation: 2762.393664321567\n"
     ]
    }
   ],
   "source": [
    "for machine in svrs:\n",
    "    score = cross_val_score(machine, housing_prepared,  housing_labels, \n",
    "                           cv = 10, scoring = \"neg_mean_squared_error\")\n",
    "    display_scores(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "                   param_distributions=[{'max_features': [2, 4, 6, 8],\n",
       "                                         'n_estimators': [3, 10, 30]},\n",
       "                                        {'bootstrap': [False],\n",
       "                                         'max_features': [2, 3, 4],\n",
       "                                         'n_estimators': [3, 10]}],\n",
       "                   return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = [\n",
    "{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "grid_search = RandomizedSearchCV(rf, grid, cv = 5, scoring = \"neg_mean_squared_error\",\n",
    "                                return_train_score = True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=6, n_estimators=30)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestRegressor()\n",
    "\n",
    "numerical_pipe = Pipeline([\n",
    "    (\"Impute\", SimpleImputer(strategy = \"median\")),\n",
    "    (\"Add\", Custom()),\n",
    "    (\"Standard\", StandardScaler())\n",
    "])\n",
    "\n",
    "numerical_variables = list(housing)[:-1]\n",
    "categorical_variables = [list(housing)[-1]]\n",
    "added_varibles = [\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"]\n",
    "\n",
    "all_pipe = ColumnTransformer([\n",
    "    (\"Numerical\", numerical_pipe, numerical_variables),\n",
    "    (\"Categorical\", OneHotEncoder(), categorical_variables)\n",
    "])\n",
    "\n",
    "class Most(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numerical_attributes = None ,factor_categories = None, y = None, model = None):\n",
    "        self.numerical_attributes = numerical_attributes\n",
    "        self.factor_categories = factor_categories\n",
    "        self.y = y\n",
    "        self.model = model\n",
    "    def fit(self, X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        grid = [\n",
    "                {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "                {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "                ]\n",
    "        grid_search = GridSearchCV(self.model, grid, cv = 5, scoring = \"neg_mean_squared_error\")\n",
    "        grid_search.fit(X, self.y)\n",
    "        feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "        attributes = self.numerical_attributes + self.factor_categories.tolist()\n",
    "        chosen = sorted(zip(feature_importances, attributes), reverse = True)[:5] \n",
    "        return [tup[1] for tup in chosen] \n",
    "\n",
    "features_pipe = Pipeline([\n",
    "    (\"Transform\", all_pipe),\n",
    "    (\"Getting_attrs\", Most(numerical_attributes = numerical_variables + added_variables,\n",
    "                           factor_categories = housing.ocean_proximity.unique(),\n",
    "                           y = housing_labels, model = rf3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['median_income',\n",
       " 'NEAR OCEAN',\n",
       " 'population_per_household',\n",
       " 'bedrooms_per_room',\n",
       " 'longitude']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pipe.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion de un pipeline para los atributos numericos\n",
    "\n",
    "numerical_pipeline =  Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy = \"median\")),\n",
    "    (\"adding_attrs\", Custom()),\n",
    "    (\"Standarizing\", StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creando un columtransformer para procesar los datos categoricos junto con los numericos\n",
    "\n",
    "num_vars = list(housing)[:-1]\n",
    "cat_vars = [list(housing)[-1]]\n",
    "mixed_transformer = ColumnTransformer([\n",
    "    (\"Numerical\", numerical_pipeline, num_vars),\n",
    "    (\"Categorical\", OneHotEncoder(), cat_vars)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion de una clase que prediga sobre un conjunto de datos\n",
    "\n",
    "class Predictor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model = None, y = None):\n",
    "        self.model = model\n",
    "        self.y = y\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        self.model.fit(X, self.y)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf4 = RandomForestRegressor()\n",
    "\n",
    "pipeline_predictor = Pipeline([\n",
    "    (\"transform\", mixed_transformer),\n",
    "    (\"predict\", Predictor(model = rf4, y = housing_labels))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([266378.  , 328824.  , 224084.  , ..., 100937.  , 210656.  ,\n",
       "       466197.74])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_predictor.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forma eficiente\n",
    "pipeline_predictor2 = Pipeline([\n",
    "    (\"transform\", mixed_transformer),\n",
    "    (\"Random_Forest\", RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transform',\n",
       "                 ColumnTransformer(transformers=[('Numerical',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('adding_attrs',\n",
       "                                                                   Custom()),\n",
       "                                                                  ('Standarizing',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['longitude', 'latitude',\n",
       "                                                   'housing_median_age',\n",
       "                                                   'total_rooms',\n",
       "                                                   'total_bedrooms',\n",
       "                                                   'population', 'households',\n",
       "                                                   'median_income']),\n",
       "                                                 ('Categorical',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['ocean_proximity'])])),\n",
       "                ('Random_Forest', RandomForestRegressor())])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_predictor2.fit(housing, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([272979.  , 327320.04, 230563.  , ..., 105095.  , 210775.  ,\n",
       "       435950.57])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_predictor2.predict(housing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
